{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as num\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import math\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robot 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data= pd.read_csv('RobotDataset/Robot1', sep=\" \", header=None)\n",
    "# data=data.drop(columns=0)\n",
    "# data.columns = [\"class\",\"a1\",\"a2\",\"a3\",\"a4\",\"a5\",\"a6\",\"Id\"]\n",
    "# train_data=data.sample(frac=0.8,random_state=200)\n",
    "# validation_data=data.drop(train_data.index)\n",
    "# # # for testing \n",
    "# # validation_data=pd.read_csv(sys.args[1],sep=\" \", header=None)\n",
    "# # validation_data=validation_data.drop(columns=0)\n",
    "# # validation_data.columns=[\"class\",\"a1\",\"a2\",\"a3\",\"a4\",\"a5\",\"a6\",\"Id\"]\n",
    "\n",
    "# max_value_k= int(math.ceil(math.sqrt(len(train_data.index))))\n",
    "# list_attributes=[\"a1\",\"a2\",\"a3\",\"a4\",\"a5\",\"a6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_value(validation_data ,list_attributes,train_data,k_value,type_cal):\n",
    "    dict_value={}\n",
    "    list_value=[]\n",
    "    validation_prediction=[]\n",
    "    for validate_index, validate_row in validation_data.iterrows():\n",
    "        dict_value={}\n",
    "        dict_result={}\n",
    "        for train_index, train_row in train_data.iterrows():\n",
    "            if type_cal==0:\n",
    "#                 euclidean\n",
    "                sum_value=0.0\n",
    "                for attr in list_attributes:\n",
    "                    sum_value=sum_value + ((validate_row[attr]-train_row[attr])**2)\n",
    "                sum_value=(sum_value**0.5)\n",
    "            elif type_cal==1:\n",
    "#                 Manhatan\n",
    "                sum_value=0.0\n",
    "                for attr in list_attributes:\n",
    "                    sum_value=sum_value + abs(validate_row[attr]-train_row[attr])\n",
    "                \n",
    "            elif type_cal==2:\n",
    "#                 Minkowski\n",
    "                sum_value=0.0\n",
    "                for attr in list_attributes:\n",
    "                    sum_value=sum_value + (abs(validate_row[attr]-train_row[attr])**1.5)\n",
    "                sum_value=math.pow(sum_value,1/1.5)\n",
    "            elif type_cal==3:\n",
    "#                 cosine \n",
    "                sum_value=0.0\n",
    "                x_y=0.0\n",
    "                x_2=0.0\n",
    "                y_2=0.0\n",
    "                for attr in list_attributes:\n",
    "                    x_y = x_y + (validate_row[attr]*train_row[attr])\n",
    "                    x_2 = x_2 + (train_row[attr]**2)\n",
    "                    y_2 = y_2 + (validate_row[attr]**2)\n",
    "                    \n",
    "                x_2=(x_2**0.5)\n",
    "                y_2=(y_2**0.5)\n",
    "                sum_value=1-(x_y/(x_2*y_2))\n",
    "            dict_value.setdefault(sum_value,[])\n",
    "            dict_value[sum_value].append(train_index)\n",
    "            dict_result.setdefault(sum_value,[])\n",
    "            dict_result[sum_value].append(train_row['class'])\n",
    "#         print dict_value\n",
    "#         print dict_result\n",
    "        current_k=0\n",
    "        res={}\n",
    "#         print(train_data['class'].unique())\n",
    "        for key in train_data['class'].unique():\n",
    "            res[key]=0\n",
    "        l=dict_result.keys()\n",
    "        l.sort()\n",
    "        for key in l:\n",
    "            if current_k<k_value:\n",
    "                for i in dict_result[key]:\n",
    "                    if current_k<k_value:\n",
    "                        for j in res.keys():\n",
    "                            if j==i:\n",
    "                                res[j]=res[j]+1\n",
    "                                current_k=current_k+1\n",
    "                    else:\n",
    "                        break\n",
    "            else :\n",
    "                break\n",
    "        max_v=0\n",
    "        predication=0\n",
    "#         print(res.keys())\n",
    "        for key in res.keys():\n",
    "            if res[key]>max_v:\n",
    "                predication=key\n",
    "                max_v=res[key]\n",
    "    \n",
    "        validation_prediction.append(predication)\n",
    "    return validation_prediction        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_preformance(target_value,pridected_value):\n",
    "    t_p=0\n",
    "    f_p=0\n",
    "    t_n=0\n",
    "    f_n=0\n",
    "    for i in range(len(target_value)):\n",
    "        if target_value[i]==0 and target_value[i]==pridected_value[i]:\n",
    "            t_n=t_n+1\n",
    "        elif target_value[i]==1 and target_value[i]==pridected_value[i]:\n",
    "            t_p=t_p+1\n",
    "        elif pridected_value[i]==1 and target_value[i]==0:\n",
    "            f_p=f_p+1\n",
    "        elif pridected_value[i]==0 and target_value[i]==1:\n",
    "            f_n=f_n+1\n",
    "    if t_p!=0:\n",
    "        accuracy=(t_n+t_p)/float(t_n+t_p+f_p+f_n)\n",
    "\n",
    "        precision=(t_p)/float(t_p+f_p)\n",
    "        recall=(t_p)/float(t_p+f_n)\n",
    "        a=1/precision\n",
    "        b=1/recall\n",
    "        f1_score=2/(a+b)\n",
    "    else :\n",
    "        accuracy=0\n",
    "        precision=0\n",
    "        recall=0\n",
    "        f1_score=0\n",
    "#     print \"ture positive\",t_p\n",
    "#     print \"false positive\",f_p\n",
    "#     print \"false negative\",f_n\n",
    "#     print \"ture negative\",t_n\n",
    "    \n",
    "    print \"Accuracy \",accuracy\n",
    "    print \"Precision \",precision\n",
    "    print \"Recall \",recall\n",
    "    print \"F1 Score\",f1_score\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print train_data.iloc[117]\n",
    "print \"Robot 1\"\n",
    "ac_list_robot=[]\n",
    "actual_value=validation_data['class'].tolist()\n",
    "dict_ac={0:[],1:[],2:[],3:[]}\n",
    "for i in range(1,max_value_k+1,2):\n",
    "    print \"k-value =\"+str(i)\n",
    "    for j in range(4):\n",
    "        if j == 0:\n",
    "            print \"Euclidean Measure\"\n",
    "        elif j==1:\n",
    "            print \"Manhantan Measure\"\n",
    "        elif j==2:\n",
    "            print \"Minkowski Measure\"\n",
    "        elif j==3:\n",
    "            print \"Cosine Measure\"\n",
    "        prediction=check_value(validation_data,list_attributes,train_data,i,j)\n",
    "#     print prediction\n",
    "        ac=calc_preformance(actual_value,prediction)\n",
    "        dict_ac[j].append(ac)\n",
    "#             ac_list_robot.append(ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "list_k_value=range(1,max_value_k+1,2)\n",
    "for i in range(4):\n",
    "    plt.plot(list_k_value,dict_ac[i])\n",
    "    plt.title('k-value vs accuracy')\n",
    "    plt.xlabel('k-value')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1].values  \n",
    "y = data.iloc[:, 4].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train=train_data.iloc[:,:-1].values\n",
    "X_test=validation_data.iloc[:,:-1].values\n",
    "y_train =train_data.iloc[:,4].values\n",
    "y_test=validation_data.iloc[:,4].values\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "for i in range(1,max_value_k+1,2):\n",
    "    classifier = KNeighborsClassifier(n_neighbors=i)  \n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "#     print(confusion_matrix(y_test, y_pred))  \n",
    "# print(classification_report(y_test, y_pred)) \n",
    "    print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robot 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Robot 2\"\n",
    "data_robot= pd.read_csv('RobotDataset/Robot2', sep=\" \", header=None)\n",
    "data_robot=data_robot.drop(columns=0)\n",
    "dict_robot2_ac={0:[],1:[],2:[],3:[]}\n",
    "data_robot.columns = [\"class\",\"a1\",\"a2\",\"a3\",\"a4\",\"a5\",\"a6\",\"Id\"]\n",
    "train_data_robot=data_robot.sample(frac=0.8,random_state=200)\n",
    "validation_data_robot=data_robot.drop(train_data_robot.index)\n",
    "# from sklearn.model_selection import train_test_split  \n",
    "# train_data_robot, validation_data_robot= train_test_split(data_robot, test_size=0.2)\n",
    "# validation_data_robot=pd.read_csv(sys.args[1],sep=\" \", header=None)\n",
    "# validation_data_robot=validation_data_robot.drop(columns=0)\n",
    "# validation_data_robot.columns=[\"class\",\"a1\",\"a2\",\"a3\",\"a4\",\"a5\",\"a6\",\"Id\"]\n",
    "\n",
    "max_value_k= int(math.ceil(math.sqrt(len(train_data_robot.index))))\n",
    "list_attributes_robot=[\"a1\",\"a2\",\"a3\",\"a4\",\"a5\",\"a6\"]\n",
    "actual_value_robot=validation_data_robot['class'].tolist()\n",
    "ac_list_robot2=[]\n",
    "for i in range(1,max_value_k+1,2):\n",
    "    print \"k-value =\"+str(i)\n",
    "    for j in range(4):\n",
    "        if j == 0:\n",
    "            print \"Euclidean Measure\"\n",
    "        elif j==1:\n",
    "            print \"Manhantan Measure\"\n",
    "        elif j==2:\n",
    "            print \"Minkowski Measure\"\n",
    "        elif j==3:\n",
    "            print \"Cosine Measure\"\n",
    "#     print i\n",
    "        prediction=check_value(validation_data_robot,list_attributes_robot,train_data_robot,i,j)\n",
    "#     print prediction\n",
    "        ac=calc_preformance(actual_value_robot,prediction)\n",
    "        dict_robot2_ac[j].append(ac)\n",
    "#       if j==0:\n",
    "#             ac_list_robot2.append(ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "list_k_value=range(1,max_value_k+1,2)\n",
    "for i in range(4):\n",
    "    plt.plot(list_k_value,dict_robot2_ac[i])\n",
    "    plt.title('k-value vs accuracy')\n",
    "    plt.xlabel('k-value')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train=train_data_robot.iloc[:,:-1].values\n",
    "X_test=validation_data_robot.iloc[:,:-1].values\n",
    "y_train =train_data_robot.iloc[:,4].values\n",
    "y_test=validation_data_robot.iloc[:,4].values\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "for i in range(1,max_value_k+1,2):\n",
    "    classifier = KNeighborsClassifier(n_neighbors=i)  \n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "    print(confusion_matrix(y_test, y_pred))  \n",
    "# print(classification_report(y_test, y_pred)) \n",
    "    print \"k-value=\"+str(i)\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_preformance_iris(target_value,pridected_value):\n",
    "    accuracy_list=[]\n",
    "    precision_list=[]\n",
    "    recall_list=[]\n",
    "    f1_score_list=[]\n",
    "    li =['Iris-setosa','Iris-virginica','Iris-versicolor' ]\n",
    "#     key='Iris-setosa'\n",
    "    for key in li:\n",
    "        t_p=0\n",
    "        f_p=0\n",
    "        t_n=0\n",
    "        f_n=0\n",
    "        for i in range(len(target_value)): \n",
    "            if target_value[i]==key and target_value[i]==pridected_value[i]:\n",
    "                t_p=t_p+1\n",
    "            elif  target_value[i]!=key and target_value[i]==pridected_value[i]:\n",
    "                t_n=t_n+1\n",
    "            elif pridected_value[i]==key and  target_value[i]!=key:\n",
    "                f_p=f_p+1\n",
    "            elif pridected_value[i]!=key and target_value[i]==key:\n",
    "                f_n=f_n+1\n",
    "#             else:\n",
    "#                 print \"se\"\n",
    "        if t_p!=0:\n",
    "            accuracy=(t_n+t_p)/float(t_n+t_p+f_p+f_n)\n",
    "\n",
    "            precision=(t_p)/float(t_p+f_p)\n",
    "            recall=(t_p)/float(t_p+f_n)\n",
    "            a=1/precision\n",
    "            b=1/recall\n",
    "            f1_score=2/(a+b)\n",
    "        else :\n",
    "            accuracy=0\n",
    "            precision=0\n",
    "            recall=0\n",
    "            f1_score=0\n",
    "        accuracy_list.append(accuracy)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_score_list.append(f1_score)\n",
    "    print \"Accuracy \",sum(accuracy_list)/float(len(li))\n",
    "#     print \"Precision \",sum(precision_list)/float(len(li))\n",
    "#     print \"Recall \",sum(recall_list)/len(li)\n",
    "#     print \"F1 Score\",sum(f1_score_list)/len(li)\n",
    "    return sum(accuracy_list)/float(len(li))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris\n",
      "k-value = 1\n",
      "Euclidean Measure\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         8\n",
      " Iris-virginica       1.00      0.85      0.92        13\n",
      "Iris-versicolor       0.75      1.00      0.86         6\n",
      "\n",
      "      micro avg       0.93      0.93      0.93        27\n",
      "      macro avg       0.92      0.95      0.92        27\n",
      "   weighted avg       0.94      0.93      0.93        27\n",
      "\n",
      "Accuracy 0.9259259259259259\n",
      "Manhantan Measure\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         8\n",
      " Iris-virginica       1.00      0.85      0.92        13\n",
      "Iris-versicolor       0.75      1.00      0.86         6\n",
      "\n",
      "      micro avg       0.93      0.93      0.93        27\n",
      "      macro avg       0.92      0.95      0.92        27\n",
      "   weighted avg       0.94      0.93      0.93        27\n",
      "\n",
      "Accuracy 0.9259259259259259\n",
      "Minkowski Measure\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         8\n",
      " Iris-virginica       1.00      0.85      0.92        13\n",
      "Iris-versicolor       0.75      1.00      0.86         6\n",
      "\n",
      "      micro avg       0.93      0.93      0.93        27\n",
      "      macro avg       0.92      0.95      0.92        27\n",
      "   weighted avg       0.94      0.93      0.93        27\n",
      "\n",
      "Accuracy 0.9259259259259259\n",
      "Cosine Measure\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         8\n",
      " Iris-virginica       0.92      0.92      0.92        13\n",
      "Iris-versicolor       0.83      0.83      0.83         6\n",
      "\n",
      "      micro avg       0.93      0.93      0.93        27\n",
      "      macro avg       0.92      0.92      0.92        27\n",
      "   weighted avg       0.93      0.93      0.93        27\n",
      "\n",
      "Accuracy 0.9259259259259259\n",
      "k-value = 3\n",
      "Euclidean Measure\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         8\n",
      " Iris-virginica       1.00      0.77      0.87        13\n",
      "Iris-versicolor       0.67      1.00      0.80         6\n",
      "\n",
      "      micro avg       0.89      0.89      0.89        27\n",
      "      macro avg       0.89      0.92      0.89        27\n",
      "   weighted avg       0.93      0.89      0.89        27\n",
      "\n",
      "Accuracy 0.8888888888888888\n",
      "Manhantan Measure\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         8\n",
      " Iris-virginica       1.00      0.77      0.87        13\n",
      "Iris-versicolor       0.67      1.00      0.80         6\n",
      "\n",
      "      micro avg       0.89      0.89      0.89        27\n",
      "      macro avg       0.89      0.92      0.89        27\n",
      "   weighted avg       0.93      0.89      0.89        27\n",
      "\n",
      "Accuracy 0.8888888888888888\n",
      "Minkowski Measure\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         8\n",
      " Iris-virginica       1.00      0.77      0.87        13\n",
      "Iris-versicolor       0.67      1.00      0.80         6\n",
      "\n",
      "      micro avg       0.89      0.89      0.89        27\n",
      "      macro avg       0.89      0.92      0.89        27\n",
      "   weighted avg       0.93      0.89      0.89        27\n",
      "\n",
      "Accuracy 0.8888888888888888\n",
      "Cosine Measure\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         8\n",
      " Iris-virginica       0.92      0.85      0.88        13\n",
      "Iris-versicolor       0.71      0.83      0.77         6\n",
      "\n",
      "      micro avg       0.89      0.89      0.89        27\n",
      "      macro avg       0.88      0.89      0.88        27\n",
      "   weighted avg       0.90      0.89      0.89        27\n",
      "\n",
      "Accuracy 0.8888888888888888\n",
      "k-value = 5\n",
      "Euclidean Measure\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         8\n",
      " Iris-virginica       1.00      0.77      0.87        13\n",
      "Iris-versicolor       0.67      1.00      0.80         6\n",
      "\n",
      "      micro avg       0.89      0.89      0.89        27\n",
      "      macro avg       0.89      0.92      0.89        27\n",
      "   weighted avg       0.93      0.89      0.89        27\n",
      "\n",
      "Accuracy 0.8888888888888888\n",
      "Manhantan Measure\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         8\n",
      " Iris-virginica       1.00      0.77      0.87        13\n",
      "Iris-versicolor       0.67      1.00      0.80         6\n",
      "\n",
      "      micro avg       0.89      0.89      0.89        27\n",
      "      macro avg       0.89      0.92      0.89        27\n",
      "   weighted avg       0.93      0.89      0.89        27\n",
      "\n",
      "Accuracy 0.8888888888888888\n",
      "Minkowski Measure\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         8\n",
      " Iris-virginica       1.00      0.77      0.87        13\n",
      "Iris-versicolor       0.67      1.00      0.80         6\n",
      "\n",
      "      micro avg       0.89      0.89      0.89        27\n",
      "      macro avg       0.89      0.92      0.89        27\n",
      "   weighted avg       0.93      0.89      0.89        27\n",
      "\n",
      "Accuracy 0.8888888888888888\n",
      "Cosine Measure\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         8\n",
      " Iris-virginica       1.00      0.85      0.92        13\n",
      "Iris-versicolor       0.75      1.00      0.86         6\n",
      "\n",
      "      micro avg       0.93      0.93      0.93        27\n",
      "      macro avg       0.92      0.95      0.92        27\n",
      "   weighted avg       0.94      0.93      0.93        27\n",
      "\n",
      "Accuracy 0.9259259259259259\n",
      "k-value = 7\n",
      "Euclidean Measure\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         8\n",
      " Iris-virginica       1.00      0.77      0.87        13\n",
      "Iris-versicolor       0.67      1.00      0.80         6\n",
      "\n",
      "      micro avg       0.89      0.89      0.89        27\n",
      "      macro avg       0.89      0.92      0.89        27\n",
      "   weighted avg       0.93      0.89      0.89        27\n",
      "\n",
      "Accuracy 0.8888888888888888\n",
      "Manhantan Measure\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         8\n",
      " Iris-virginica       1.00      0.77      0.87        13\n",
      "Iris-versicolor       0.67      1.00      0.80         6\n",
      "\n",
      "      micro avg       0.89      0.89      0.89        27\n",
      "      macro avg       0.89      0.92      0.89        27\n",
      "   weighted avg       0.93      0.89      0.89        27\n",
      "\n",
      "Accuracy 0.8888888888888888\n",
      "Minkowski Measure\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         8\n",
      " Iris-virginica       1.00      0.77      0.87        13\n",
      "Iris-versicolor       0.67      1.00      0.80         6\n",
      "\n",
      "      micro avg       0.89      0.89      0.89        27\n",
      "      macro avg       0.89      0.92      0.89        27\n",
      "   weighted avg       0.93      0.89      0.89        27\n",
      "\n",
      "Accuracy 0.8888888888888888\n",
      "Cosine Measure\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         8\n",
      " Iris-virginica       1.00      0.85      0.92        13\n",
      "Iris-versicolor       0.75      1.00      0.86         6\n",
      "\n",
      "      micro avg       0.93      0.93      0.93        27\n",
      "      macro avg       0.92      0.95      0.92        27\n",
      "   weighted avg       0.94      0.93      0.93        27\n",
      "\n",
      "Accuracy 0.9259259259259259\n",
      "k-value = 9\n",
      "Euclidean Measure\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         8\n",
      " Iris-virginica       1.00      0.77      0.87        13\n",
      "Iris-versicolor       0.67      1.00      0.80         6\n",
      "\n",
      "      micro avg       0.89      0.89      0.89        27\n",
      "      macro avg       0.89      0.92      0.89        27\n",
      "   weighted avg       0.93      0.89      0.89        27\n",
      "\n",
      "Accuracy 0.8888888888888888\n",
      "Manhantan Measure\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         8\n",
      " Iris-virginica       1.00      0.77      0.87        13\n",
      "Iris-versicolor       0.67      1.00      0.80         6\n",
      "\n",
      "      micro avg       0.89      0.89      0.89        27\n",
      "      macro avg       0.89      0.92      0.89        27\n",
      "   weighted avg       0.93      0.89      0.89        27\n",
      "\n",
      "Accuracy 0.8888888888888888\n",
      "Minkowski Measure\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         8\n",
      " Iris-virginica       1.00      0.77      0.87        13\n",
      "Iris-versicolor       0.67      1.00      0.80         6\n",
      "\n",
      "      micro avg       0.89      0.89      0.89        27\n",
      "      macro avg       0.89      0.92      0.89        27\n",
      "   weighted avg       0.93      0.89      0.89        27\n",
      "\n",
      "Accuracy 0.8888888888888888\n",
      "Cosine Measure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         8\n",
      " Iris-virginica       1.00      0.85      0.92        13\n",
      "Iris-versicolor       0.75      1.00      0.86         6\n",
      "\n",
      "      micro avg       0.93      0.93      0.93        27\n",
      "      macro avg       0.92      0.95      0.92        27\n",
      "   weighted avg       0.94      0.93      0.93        27\n",
      "\n",
      "Accuracy 0.9259259259259259\n",
      "k-value = 11\n",
      "Euclidean Measure\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         8\n",
      " Iris-virginica       1.00      0.85      0.92        13\n",
      "Iris-versicolor       0.75      1.00      0.86         6\n",
      "\n",
      "      micro avg       0.93      0.93      0.93        27\n",
      "      macro avg       0.92      0.95      0.92        27\n",
      "   weighted avg       0.94      0.93      0.93        27\n",
      "\n",
      "Accuracy 0.9259259259259259\n",
      "Manhantan Measure\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         8\n",
      " Iris-virginica       1.00      0.77      0.87        13\n",
      "Iris-versicolor       0.67      1.00      0.80         6\n",
      "\n",
      "      micro avg       0.89      0.89      0.89        27\n",
      "      macro avg       0.89      0.92      0.89        27\n",
      "   weighted avg       0.93      0.89      0.89        27\n",
      "\n",
      "Accuracy 0.8888888888888888\n",
      "Minkowski Measure\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         8\n",
      " Iris-virginica       1.00      0.77      0.87        13\n",
      "Iris-versicolor       0.67      1.00      0.80         6\n",
      "\n",
      "      micro avg       0.89      0.89      0.89        27\n",
      "      macro avg       0.89      0.92      0.89        27\n",
      "   weighted avg       0.93      0.89      0.89        27\n",
      "\n",
      "Accuracy 0.8888888888888888\n",
      "Cosine Measure\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         8\n",
      " Iris-virginica       1.00      0.77      0.87        13\n",
      "Iris-versicolor       0.67      1.00      0.80         6\n",
      "\n",
      "      micro avg       0.89      0.89      0.89        27\n",
      "      macro avg       0.89      0.92      0.89        27\n",
      "   weighted avg       0.93      0.89      0.89        27\n",
      "\n",
      "Accuracy 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "print \"Iris\"\n",
    "dict_iris_ac={0:[],1:[],2:[],3:[]}\n",
    "data_iris= pd.read_csv('Iris/Iris.csv')\n",
    "data_iris.columns = [\"a1\",\"a2\",\"a3\",\"a4\",\"class\"]\n",
    "train_data_iris=data_iris.sample(frac=0.8)\n",
    "validation_data_iris=data_iris.drop(train_data_iris.index)\n",
    "# from sklearn.model_selection import train_test_split  \n",
    "# train_data_iris, validation_data_iris= train_test_split(data_iris, test_size=0.2)\n",
    "# validation_data_iris=pd.read_csv(sys.args[1],sep=\" \", header=None)\n",
    "# validation_data_iris.columns=[\"a1\",\"a2\",\"a3\",\"a4\",\"class\"]\n",
    "\n",
    "max_value_k_iris= int(math.ceil(math.sqrt(len(train_data_iris.index))))\n",
    "list_attributes_iris=[\"a1\",\"a2\",\"a3\",\"a4\"]\n",
    "actual_value_iris=validation_data_iris['class'].tolist()\n",
    "ac_list_iris=[]\n",
    "for i in range(1,max_value_k_iris+1,2):\n",
    "    print \"k-value = \"+str(i)\n",
    "    for j in range(4):\n",
    "        if j == 0:\n",
    "            print \"Euclidean Measure\"\n",
    "        elif j==1:\n",
    "            print \"Manhantan Measure\"\n",
    "        elif j==2:\n",
    "            print \"Minkowski Measure\"\n",
    "        elif j==3:\n",
    "            print \"Cosine Measure\"\n",
    "#     print i\n",
    "        prediction_iris=check_value(validation_data_iris,list_attributes_iris,train_data_iris,i,j)\n",
    "    \n",
    "#     print prediction_iris\n",
    "#     print actual_value_iris\n",
    "        target_names = ['Iris-setosa','Iris-virginica','Iris-versicolor' ]\n",
    "        print(classification_report(actual_value_iris, prediction_iris, target_names=target_names))\n",
    "        ac= accuracy_score(actual_value_iris,prediction_iris)\n",
    "        print \"Accuracy \"+str(ac)\n",
    "#         if j==0:\n",
    "#             ac_list_iris.append(ac)\n",
    "        dict_iris_ac[j].append(ac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "list_k_value=range(1,max_value_k_iris+1,2)\n",
    "for i in range(4):\n",
    "\n",
    "    plt.plot(list_k_value,dict_iris_ac[i])\n",
    "\n",
    "    plt.title('k-value vs accuracy for iris')\n",
    "    plt.xlabel('k-value')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-value = 1\n",
      "Accuracy 0.9259259259259259\n",
      "k-value = 3\n",
      "Accuracy 0.9259259259259259\n",
      "k-value = 5\n",
      "Accuracy 0.8888888888888888\n",
      "k-value = 7\n",
      "Accuracy 0.8888888888888888\n",
      "k-value = 9\n",
      "Accuracy 0.8888888888888888\n",
      "k-value = 11\n",
      "Accuracy 0.9259259259259259\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train=train_data_iris.iloc[:,:-1].values\n",
    "X_test=validation_data_iris.iloc[:,:-1].values\n",
    "y_train =train_data_iris.iloc[:,4].values\n",
    "y_test=validation_data_iris.iloc[:,4].values\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "for i in range(1,max_value_k_iris+1,2):\n",
    "    classifier = KNeighborsClassifier(n_neighbors=i)  \n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "#     print(confusion_matrix(y_test, y_pred))  \n",
    "# print(classification_report(y_test, y_pred)) \n",
    "    print \"k-value = \"+str(i)\n",
    "    print(\"Accuracy \"+str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
